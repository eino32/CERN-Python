{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.constants\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import quad\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.ticker import LogFormatter\n",
    "import os\n",
    "%matplotlib qt\n",
    "# %matplotlib inline\n",
    "import datetime as dt\n",
    "pd.set_option('display.max_rows', 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data and preparing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the file and create dataframe\n",
    "#excplicitly state the part\n",
    "#path = r'C:\\Users\\einot\\OneDrive\\Documents\\CERN VScode\\CERN-Python\\4K desorption measurements\\Cu sample\\EGA fully in\\S1 no preinjection at cold temps'\n",
    "#mid = pd.read_csv(os.path.join(path, \"MID.tsv\"), sep=\"\\t\", skiprows=lambda x: x<=11, on_bad_lines=\"skip\")\n",
    "\n",
    "#List molecule masses used in MID scan\n",
    "\n",
    "#masslist = [2,4,12,15,16,18,28,32,40,44]\n",
    "\n",
    "#Define datetime format\n",
    "#MID_datetime = \"%Y/%m/%d %H:%M:%S.%f\"\n",
    "\n",
    "#Reformat time values\n",
    "def timeformat(df,format):\n",
    "    new_df = df.copy()\n",
    "    for idx, col in enumerate(df):\n",
    "        if idx % 2 == 0:  # Check if the column index is even (every other column)\n",
    "            pandas_timestamp = pd.to_datetime(df[col], format=format)\n",
    "            timestamp = pandas_timestamp.dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "            new_df[col] = timestamp  # Replace the time column in the new dataframe\n",
    "    return new_df\n",
    "\n",
    "#call the function with correct parameters to modify MID dataframe\n",
    "#mid = timeformat(mid,MID_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaclogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n#call the function with correct parameters to modify vaclogger dataframe\\nvaclog = elapsed_time(vaclog,\"Time\",vaclog_datetime) '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #Reading in the file\n",
    "vaclog = pd.read_csv(os.path.join(path, \"vaclog\"), sep=\"\\t\")\n",
    "\n",
    "#Define original datetime format\n",
    "vaclog_datetime = \"%d/%m/%Y %H:%M:%S\"\n",
    " \"\"\"\n",
    "#Adding an elapsed time column for temperature fits\n",
    "def elapsed_time(df,timecol,format):\n",
    "    new_df = df.copy()\n",
    "    pandas_timestamp = pd.to_datetime(new_df[timecol],format=format)\n",
    "    runtime = (pandas_timestamp-pandas_timestamp[0]).dt.total_seconds()\n",
    "    insert_idx = df.columns.get_loc(timecol) + 1  # Get the index to insert the new column\n",
    "    new_df.insert(insert_idx,\"Elapsed time\", runtime)\n",
    "    reformat = pandas_timestamp.dt.strftime('%d-%m-%Y %H:%M:%S') #New timestamp format for plotting\n",
    "    print(reformat)\n",
    "    new_df[timecol] = reformat\n",
    "    new_df[timecol] = pd.to_datetime(new_df[timecol],format='%d-%m-%Y %H:%M:%S') #convert to pd datetime\n",
    "    \n",
    "    return new_df\n",
    "\"\"\" \n",
    "#call the function with correct parameters to modify vaclogger dataframe\n",
    "vaclog = elapsed_time(vaclog,\"Time\",vaclog_datetime) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(root):\n",
    "    #Define datetime formats\n",
    "    MID_datetime = \"%Y/%m/%d %H:%M:%S.%f\"\n",
    "    vaclog_datetime = \"%d/%m/%Y %H:%M:%S\"\n",
    "    hv_datetime = \"%d/%m/%Y %H:%M:%S.%f\"\n",
    "    \n",
    "    #Create an empty dictionary to store processed dataframes\n",
    "    dataframes = {}\n",
    "\n",
    "    # Iterate over the subdirectories starting from the specified directory\n",
    "    for dirpath, dirs, files in os.walk(root):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(dirpath,filename)\n",
    "            #print(filepath)\n",
    "            # Create a variable name using the relative path\n",
    "            relative_path = os.path.relpath(root, dirpath)\n",
    "            #print(relative_path)\n",
    "            variable_name = os.path.join(relative_path, os.path.splitext(filename)[0])\n",
    "            #print(variable_name)\n",
    "            #Read in the MID file\n",
    "            if filename == \"MID.tsv\":\n",
    "                mid = pd.read_csv(filepath, sep=\"\\t\", skiprows=lambda x: x<=11, on_bad_lines=\"skip\")\n",
    "                mid = timeformat(mid, MID_datetime)\n",
    "\n",
    "                # Create a variable name using the base name of the MID filename\n",
    "                #variable_name = os.path.splitext(filename)[0]\n",
    "\n",
    "                # Store the MID dataframe using the variable name\n",
    "                dataframes[variable_name] = mid\n",
    "\n",
    "            #Read in the vaclog file\n",
    "            elif filename == \"vaclog\":\n",
    "                vaclog = elapsed_time(pd.read_csv(filepath, sep=\"\\t\"), \"Time\", vaclog_datetime)\n",
    "                print(vaclog)\n",
    "                # Create a variable name using the base name of the MID filename\n",
    "                #variable_name = os.path.splitext(filename)[0]\n",
    "\n",
    "                # Store the vaclog dataframe using the variable name\n",
    "                dataframes[variable_name] = vaclog\n",
    "\n",
    "            #Read in the hivolta file\n",
    "            elif filename == \"hv log\":\n",
    "                hv = pd.read_csv(filepath, sep=\",\")\n",
    "                hv[\"hv_grid\"] = [abs(element) * 1e-6 for element in hv[\"IMon1\"]]\n",
    "                hv[\"I_em\"] = [abs(element) * 1e-6 for element in hv[\"IMon2\"]]\n",
    "                hv[\"datetime\"] = hv['Date'] + ' ' + hv['Time']\n",
    "                hv = elapsed_time(hv, \"datetime\", hv_datetime)\n",
    "\n",
    "                # Create a variable name using the base name of the MID filename\n",
    "                #variable_name = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Store the hv dataframe using the variable name\n",
    "                dataframes[variable_name] = hv   \n",
    "            \n",
    "    return dataframes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       10-03-2023 13:34:57\n",
      "1       10-03-2023 13:34:58\n",
      "2       10-03-2023 13:35:00\n",
      "3       10-03-2023 13:35:01\n",
      "4       10-03-2023 13:35:02\n",
      "               ...         \n",
      "3798    10-03-2023 14:50:57\n",
      "3799    10-03-2023 14:50:58\n",
      "3800    10-03-2023 14:50:59\n",
      "3801    10-03-2023 14:51:00\n",
      "3802    10-03-2023 14:51:02\n",
      "Name: datetime, Length: 3803, dtype: object\n",
      ".\\hv log\n",
      "            Date          Time   VMon1   VMon2    VMon3    VMon4   VMon5  \\\n",
      "0     10/03/2023  13:34:57.748    0.00    0.08     0.06     0.10     0.0   \n",
      "1     10/03/2023  13:34:58.919    0.00    0.08     0.06     0.10     0.0   \n",
      "2     10/03/2023  13:35:00.109    0.00    0.08     0.06     0.10     0.0   \n",
      "3     10/03/2023  13:35:01.311    0.00    0.08     0.06     0.10     0.0   \n",
      "4     10/03/2023  13:35:02.488    0.00    0.08     0.06     0.10     0.0   \n",
      "...          ...           ...     ...     ...      ...      ...     ...   \n",
      "3798  10/03/2023  14:50:57.266  499.96  100.10  1000.02  1000.14  1000.1   \n",
      "3799  10/03/2023  14:50:58.456  499.96  100.10  1000.02  1000.14  1000.1   \n",
      "3800  10/03/2023  14:50:59.654  499.96  100.10  1000.02  1000.14  1000.1   \n",
      "3801  10/03/2023  14:51:00.852  499.96  100.10  1000.02  1000.14  1000.1   \n",
      "3802  10/03/2023  14:51:02.045  499.96  100.10  1000.02  1000.14  1000.1   \n",
      "\n",
      "       VMon6  VMon7  VMon8  ...    IMon5    IMon6   IMon7   IMon8  Comment  \\\n",
      "0       0.00    0.0   0.00  ...   0.0085   0.0121 -0.0084 -0.0220      NaN   \n",
      "1       0.00    0.0   0.00  ...   0.0085   0.0121 -0.0084 -0.0220      NaN   \n",
      "2       0.00    0.0   0.00  ...   0.0085   0.0121 -0.0084 -0.0220      NaN   \n",
      "3       0.00    0.0   0.00  ...   0.0085   0.0121 -0.0084 -0.0220      NaN   \n",
      "4       0.00    0.0   0.00  ...   0.0085   0.0121 -0.0084 -0.0220      NaN   \n",
      "...      ...    ...    ...  ...      ...      ...     ...     ...      ...   \n",
      "3798  499.94    0.0   0.02  ...  17.8815  17.8731 -0.0038 -0.0184      NaN   \n",
      "3799  499.94    0.0   0.02  ...  17.8784  17.8683 -0.0038 -0.0184      NaN   \n",
      "3800  499.94    0.0   0.02  ...  17.8755  17.8645 -0.0038 -0.0184      NaN   \n",
      "3801  499.94    0.0   0.02  ...  17.8723  17.8608 -0.0038 -0.0184      NaN   \n",
      "3802  499.94    0.0   0.02  ...  17.8723  17.8603 -0.0038 -0.0184      NaN   \n",
      "\n",
      "      Unnamed: 19       hv_grid          I_em            datetime  \\\n",
      "0             NaN  1.020000e-08  1.350000e-08 2023-03-10 13:34:57   \n",
      "1             NaN  1.020000e-08  1.320000e-08 2023-03-10 13:34:58   \n",
      "2             NaN  1.020000e-08  1.320000e-08 2023-03-10 13:35:00   \n",
      "3             NaN  1.020000e-08  1.320000e-08 2023-03-10 13:35:01   \n",
      "4             NaN  1.020000e-08  1.320000e-08 2023-03-10 13:35:02   \n",
      "...           ...           ...           ...                 ...   \n",
      "3798          NaN  1.440000e-08  2.280000e-08 2023-03-10 14:50:57   \n",
      "3799          NaN  1.440000e-08  2.280000e-08 2023-03-10 14:50:58   \n",
      "3800          NaN  1.450000e-08  2.280000e-08 2023-03-10 14:50:59   \n",
      "3801          NaN  1.450000e-08  2.280000e-08 2023-03-10 14:51:00   \n",
      "3802          NaN  1.450000e-08  2.280000e-08 2023-03-10 14:51:02   \n",
      "\n",
      "      Elapsed time  \n",
      "0            0.000  \n",
      "1            1.171  \n",
      "2            2.361  \n",
      "3            3.563  \n",
      "4            4.740  \n",
      "...            ...  \n",
      "3798      4559.518  \n",
      "3799      4560.708  \n",
      "3800      4561.906  \n",
      "3801      4563.104  \n",
      "3802      4564.297  \n",
      "\n",
      "[3803 rows x 24 columns]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#Accessing the files\n",
    "root = os.getcwd()\n",
    "data = process_data(root)\n",
    "\n",
    "# Access the processed dataframes using the variable names\n",
    "for variable_name, dataframe in data.items():\n",
    "    print(variable_name)\n",
    "    print(dataframe)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CernOx R-T conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempconvert(df):\n",
    "    new_df = df.copy()\n",
    "    #Temperature curve for CERNOX - for temp stability\n",
    "    A=[230.317302,-6170.1513,71837.9529,-477946.76,2.003668910085786e+6,-5.488690193047771e+6,9.830475663897528e+6,-1.111226817786569e+7,7.202477878914065e+6,-2.04194551328507e+6]\n",
    "\n",
    "    #specify fit parameters A, data (Resistance values)\n",
    "    def polyfit(param,data):\n",
    "        total=[]\n",
    "        for j in data: \n",
    "            exp=0\n",
    "            for i in range(len(param)):\n",
    "                exp += (param[i]/(math.log10(j))**i)\n",
    "            total.append(10**exp)\n",
    "        return(total)\n",
    "    col_loc = int(df.columns.get_loc(\"T-CERNOX\") + 1)    \n",
    "    new_df.insert(col_loc, \"CernOx Temp\", polyfit(A, new_df[\"T-CERNOX\"]))\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LHe level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfit(x, a, b):\n",
    "        return a * x + b\n",
    "def lhe_fit(y_val, x_val): #Normal fit without extended x-axis\n",
    "    # Curve fit for the data\n",
    "    params, cov = curve_fit(linfit, x_val, y_val)\n",
    "\n",
    "    # Straight line parameters\n",
    "    a, b = params\n",
    "\n",
    "    # Calculate the number of data points needed to reach b/a condition\n",
    "    num_points = int(abs(b / a) / (x_val[1] - x_val[0])) + 1\n",
    "\n",
    "    # Extend the fitted line to y_fit = 0\n",
    "    x_fit = np.linspace(x_val[0], (-b/a), num_points)\n",
    "\n",
    "    y_fit = linfit(x_fit, a, b)\n",
    "\n",
    "    return x_fit, y_fit, a, b\n",
    "\n",
    "def ext_fit(y_val, x_val, b_val): #extended fit with longer x-axis, user specified b-parameter\n",
    "    # Curve fit for the data\n",
    "    params, cov = curve_fit(linfit, x_val, y_val)\n",
    "\n",
    "    # Straight line parameters\n",
    "    a, b = params\n",
    "\n",
    "    # Calculate the number of data points needed to reach b/a condition\n",
    "    num_points = int(abs(b_val / a) / (x_val[1] - x_val[0])) + 1\n",
    "\n",
    "    # Extend the fitted line to y_fit = 0\n",
    "    x_fit_extended = np.linspace(x_val[0], (-b_val/a), num_points)\n",
    "\n",
    "    y_fit_extended = linfit(x_fit_extended, a, b_val)\n",
    "\n",
    "    return x_fit_extended, y_fit_extended, a, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients for gauge readings\n",
    "Applied for the gauge readings using the formula below:\n",
    "    $$\n",
    "    \\frac{p_2}{p_1}=\\sqrt \\frac{T_2}{T_1}\n",
    "    $$\n",
    "Here $p_2$ and $T_2$ are the pressure and temperature in the cold part and $p_1$, $T_1$ are the pressure, temperature the gauge is exposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.352359233288805\n"
     ]
    }
   ],
   "source": [
    "#Thermal transpiration\n",
    "T2 = 4.2\n",
    "T1 = 293\n",
    "p_coef = np.sqrt(T1/T2)\n",
    "print(p_coef)\n",
    "#N2 to H2 equivalent conversion\n",
    "CF_h2 = 2.49\n",
    "def gauge_correction(df):\n",
    "    new_df = df.copy()\n",
    "    #apply correction factors\n",
    "    ba1 = df[\"Barion_1\"]*CF_h2/p_coef\n",
    "    ba2 = df[\"Barion_2\"]*CF_h2/p_coef\n",
    "    print(ba1[0])\n",
    "    print(df[\"Barion_1\"][0])\n",
    "    new_df[\"Barion_1\"] = ba1\n",
    "    new_df[\"Barion_2\"] = ba2\n",
    "    new_df.rename(columns={\"Barion_1\": \"Barion_1 corr\", \"Barion_2\": \"Barion_2 corr\"},inplace=True)\n",
    "    print(new_df.head)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating number of molecules injected\n",
    "$$\n",
    "N=\\frac{\\Sigma dp\\cdot V_{inj}}{k_B\\cdot T}=\\frac{\\Sigma (p_{inj,t(x)}-p_{inj,t(x-1)})\\cdot V_{inj}}{k_B \\cdot T}   \\space \\left[{M}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants \n",
    "V_inj = 6.515e-5\n",
    "S_sample= 276\n",
    "\n",
    "#Getting the number of molecules N and (homogenous) coverage:\n",
    "def N_inj(df, inj_gauge):\n",
    "    #Calculate dp\n",
    "    dp = abs(np.diff(df[inj_gauge]*100)) #mbar to Pa conversion\n",
    "    # Append a 0 to the beginning of the dp array\n",
    "    dp= np.insert(dp, 0, 0)\n",
    "    N = (dp.cumsum())*V_inj/(scipy.constants.k*T1)\n",
    "    cov = N/S_sample #Molecules per cm2\n",
    "    col_loc = int(df.columns.get_loc(inj_gauge) + 1)\n",
    "    df.insert(col_loc,\"Number of molecules injected\",N)\n",
    "    df.insert(col_loc+1,\"Coverage\",cov)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments(dataframe,timecol,commentcol):\n",
    "    #print hv comments\n",
    "    #print(pd.unique(dataframe[colname]))\n",
    "    new_dataframe = dataframe.loc[:,[timecol,commentcol]]\n",
    "    #delete excess comments (hv log program writes each comment 4x)\n",
    "\n",
    "    # Find the indices of the first occurrence of each unique event\n",
    "    first_unique_indices = new_dataframe.drop_duplicates(subset=commentcol, keep=\"first\").index\n",
    "\n",
    "    #replace the comments in rows that are not the first occurrence of each unique event with NaN values\n",
    "    new_dataframe.loc[~new_dataframe.index.isin(first_unique_indices), commentcol] = np.nan\n",
    "\n",
    "    #drop NaN values\n",
    "    new_dataframe.dropna(inplace=True)\n",
    "    print(new_dataframe.index)\n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron dose calculations (only for isotherm + ESD mixed measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find:\n",
    "\n",
    "$$\n",
    "Q = \\int_{t_1}^{t_2} I \\,dt\n",
    "$$\n",
    "\n",
    "Where $t_2$ and $t_1$ are the timestamps at which an emission current reading was taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def electron_dose(hv):\\n    #define the n and n-1\\n    t_delta = hv[\"Elapsed time\"].diff(periods=1).fillna(0)\\n\\n    #dealing with missing datapoints and false integration times\\n    #Compare t_delta and I_em values: if I_em values between t_delta indexes n, n-1 are negligible, ignore this time period in integration\\n\\n\\n\\n\\n\\n    return hv '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def electron_dose(hv):\n",
    "    #define the n and n-1\n",
    "    t_delta = hv[\"Elapsed time\"].diff(periods=1).fillna(0)\n",
    "\n",
    "    #dealing with missing datapoints and false integration times\n",
    "    #Compare t_delta and I_em values: if I_em values between t_delta indexes n, n-1 are negligible, ignore this time period in integration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return hv \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpson's rule for integration (only for isotherm + ESD mixed measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "I_{Simps} = \\frac{h}{3}\\left(y_0+2 \\sum_{i=1}^{n/2-1} y_{2i}+4 \\sum_{i=1}^{n/2} y_{2i-1+y_n}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def electron_dose(df, threshold):\n",
    "    # Find the indices where the emission current is above the threshold\n",
    "    mask_above_threshold = df['I_em'] > threshold\n",
    "    print()\n",
    "    # Initialize variables\n",
    "    Q = 0\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        print(mask_above_threshold[idx])\n",
    "        if mask_above_threshold[idx]:\n",
    "            if start_idx is None:\n",
    "                start_idx = idx\n",
    "            end_idx = idx\n",
    "        else:\n",
    "            if start_idx is not None:\n",
    "                end_idx = idx - 1\n",
    "\n",
    "                # Apply Simpson's rule to the subset\n",
    "                subset = df.loc[start_idx:end_idx]\n",
    "                subset_size = len(subset)\n",
    "                h = subset['t'].diff().mean()\n",
    "\n",
    "                # Ensure the subset has at least 4 data points for Simpson's rule\n",
    "                if subset_size >= 4:\n",
    "                    even_sum = subset['I_em'].iloc[2:subset_size-2:2].sum()\n",
    "                    odd_sum = subset['I_em'].iloc[1:subset_size-1:2].sum()\n",
    "                    integral = (subset['I_em'].iloc[0] + subset['I_em'].iloc[subset_size-1] + 4 * odd_sum + 2 * even_sum) * (h / 3)\n",
    "\n",
    "                    Q += integral\n",
    "\n",
    "                start_idx = None\n",
    "                end_idx = None\n",
    "    return Q\n",
    "\n",
    "\n",
    "# Example usage\n",
    "dfdata = {'t': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "        'I_em': [200, 600, 700, 300, 800, 900, 400, 100, 50, 700, 800, 200, 500, 300, 900, 100, 200, 600, 700, 300]}\n",
    "df = pd.DataFrame(dfdata)\n",
    "\n",
    "threshold = 500\n",
    "\n",
    "Q = electron_dose(df, threshold) #Threshold for ESD - 500nA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the mathematical model PSD (ESD) dose dependence according to Malyshev:\n",
    "\n",
    "\n",
    "$$\\eta(D) = \\eta_0 \\cdot \\left(\\frac{D+D_1}{D_0+D_1} \\right)^{-a}$$\n",
    "\n",
    "Where parameters $D_0$ and $D_1$ are added to extend the applicability towards low doses in a way that the curve asymptotically approaches the constant initial ESD yield $eta_0$ as $D \\rarr 0$. $D_0$ represents the dose imparted at the lowest measurable data point and $D_1$ is used to position the end of the initial plateau. The exponent α determines the steepness, here referred to as the conditioning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for ESD dose dependence\n",
    "def esd_fit(eta_0,D,D_0,D_1,a):\n",
    "    return eta_0*((D+D_1)/(D_0+D_1))^(-a)\n",
    "\n",
    "#Use curve_fit for dependent variable D\n",
    "D_0 = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adsorption isotherms (DRK, Hobson)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model describing the physisorption isotherms for low temperatures in the submonolayer region:\n",
    "\n",
    "$\\ln\\Theta=-D\\left(k_BT\\ln\\left(\\frac{P}{P_0}\\right)\\right)^2=-B\\left(R\\,T\\ln\\left(\\frac{P}{P_0}\\right)\\right)^2$, \n",
    "\n",
    "with $k_B$ the Boltzmann constant, $R$ the gas constant, $D$ or $B$ an empirical constant linked to the vaporisation heat of the adsorbate (DR energy)  and $P_0$ the saturated vapor pressure at the temperature $T$.\n",
    "\n",
    "#### Hobson, 1995\n",
    "Hobson took $B$ to be $B=3.59\\cdot 10^{-6}\\,\\mathrm{cal^{-2}mol^{2}}$ following Halama and Aggus (https://doi.org/10.1116/1.568583 , 1975).\n",
    "#### Chill, Wilfert and Bozyk, 2019\n",
    "Chill, Wilfert and Bozyk measured isotherms between 7 and 18 K on stainless steel and found by fitting $D=3075\\,\\mathrm{eV}^{-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Wallen measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\etiirine\\\\cernbox\\\\Documents\\\\etiirinen\\\\Python\\\\H2 adsorption isotherm on HiLumi sample\\\\Wallen.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\etiirine\\cernbox\\Documents\\etiirinen\\Python\\H2 Adsorption isotherms\\H2 adsorption isotherm on HiLumi sample\\series 6\\Data analysis notebook for ads isotherms.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(filepath, delimiter\u001b[39m=\u001b[39mdelim)\u001b[39m#for wallen, use \"\\t\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m wallen \u001b[39m=\u001b[39m read_data(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39metiirine\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mcernbox\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDocuments\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39metiirinen\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPython\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mH2 adsorption isotherm on HiLumi sample\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mWallen.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\etiirine\\cernbox\\Documents\\etiirinen\\Python\\H2 Adsorption isotherms\\H2 adsorption isotherm on HiLumi sample\\series 6\\Data analysis notebook for ads isotherms.ipynb Cell 36\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(filepath, delim)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_data\u001b[39m(filepath,delim):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(filepath, delimiter\u001b[39m=\u001b[39;49mdelim)\u001b[39m#for wallen, use \"\\t\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etiirine/cernbox/Documents/etiirinen/Python/H2%20Adsorption%20isotherms/H2%20adsorption%20isotherm%20on%20HiLumi%20sample/series%206/Data%20analysis%20notebook%20for%20ads%20isotherms.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\etiirine\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\etiirine\\\\cernbox\\\\Documents\\\\etiirinen\\\\Python\\\\H2 adsorption isotherm on HiLumi sample\\\\Wallen.csv'"
     ]
    }
   ],
   "source": [
    "#reading in other data\n",
    "p_0 = 4.25e-5 #(Pa)\n",
    "p_0_mbar=p_0/100\n",
    "p_0_mbar\n",
    "S_m = 2.39e15 #molecules/cm2\n",
    "d_wallen = 3.61e4/scipy.constants.e**2 # ev^-2 to J^-2\n",
    "def read_data(filepath,delim):\n",
    "    df=pd.read_csv(filepath, delimiter=delim)#for wallen, use \"\\t\"\n",
    "    return df\n",
    "\n",
    "wallen = read_data(r'C:\\Users\\etiirine\\cernbox\\Documents\\etiirinen\\Python\\H2 adsorption isotherm on HiLumi sample\\Wallen.csv',\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fleur's data\n",
    "fleur = read_data(r'C:\\Users\\etiirine\\cernbox\\Documents\\etiirinen\\Python\\H2 adsorption isotherm on HiLumi sample\\fleurs_measurements.csv', \",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical isotherms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "b_hobson=1./528**2\n",
    "gas_constant=1.9865\n",
    "d_CWB = 3075/scipy.constants.e**2 # J^-2\n",
    "#Hobson and DRK isotherms\n",
    "def theta_hobson(p):\n",
    "    return S_m*np.exp(-b_hobson*(gas_constant*4.2*np.log(p/p_0))**2)\n",
    "def theta_drk(p,d_const):\n",
    "    return S_m*np.exp(-d_const*(scipy.constants.k*4.2*np.log(p/p_0))**2)\n",
    "fit_values = np.logspace(-18,-4,50) #Pa\n",
    "thetas=np.logspace(-7,0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the data analysis functions and writing to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining variables to the called functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining a variable for original measurement data\n",
    "vaclog = data[\".\\\\vaclog\"]\n",
    "#LHe data\n",
    "y_val = data[\".\\\\vaclog\"][\"helium\"].values\n",
    "x_val = data[\".\\\\vaclog\"][\"Elapsed time\"].values\n",
    "b_full = 560\n",
    "#Straight line fit for LHe data\n",
    "x_fit, y_fit, a, b = lhe_fit(y_val, x_val)\n",
    "#Extended fit for LHe data\n",
    "x_fit_extended, y_fit_extended, a_ext, b_full = ext_fit(y_val, x_val, b_full)\n",
    "#Calculate Number of molecules and coverage, CernOx temperature, apply gauge correction\n",
    "vaclog_new = N_inj((gauge_correction(tempconvert(vaclog))),\"injection 100mbar\")\n",
    "#Comments\n",
    "vaclog_comments = comments(vaclog,\"Time\", \"Live comments\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Writing to excel file\n",
    "def write_to_excel(filename):\n",
    "    #Insert Lhe fit data\n",
    "    lhe_fit_data = {f\"Fit x a={a:.4f}, b={b:.4f}\":x_fit,f\"Fit y a={a:.4f}, b={b:.4f}\":y_fit}\n",
    "    lhe_ext_fit_data = {f\"Extended fit x a={a_ext:.4f}, b={b_full:.4f}\":x_fit_extended,f\"Extended fit y a={a_ext:.4f}, b={b_full:.4f}\":y_fit_extended}\n",
    "    lhe_fit_df = pd.DataFrame(lhe_fit_data)\n",
    "    lhe_fit_ext_df = pd.DataFrame(lhe_ext_fit_data)\n",
    "    \n",
    "    #Write to excel\n",
    "    writer = pd.ExcelWriter(os.path.join(os.getcwd(),filename),engine=\"xlsxwriter\")\n",
    "    vaclog.to_excel(writer,sheet_name='Original data')\n",
    "    vaclog_new.to_excel(writer, sheet_name='Analysed data')\n",
    "    lhe_fit_df.to_excel(writer,sheet_name=\"LHe fit data\")\n",
    "    lhe_fit_ext_df.to_excel(writer,sheet_name=\"LHe extended fit data\")\n",
    "    writer.save()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (To complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters for plotting\n",
    "#annotation params\n",
    "font = dict(size = \"x-small\", color =\"green\", style =\"italic\",rotation=\"vertical\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8,5]\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = \"black\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.35\n",
    "\n",
    "formatter = md.DateFormatter('%H:%M')\n",
    "\n",
    "# Create the \"graphs\" folder path\n",
    "graphs_folder = os.path.join(root, 'graphs')\n",
    "\n",
    "# Ensure the \"graphs\" folder exists, if not create it\n",
    "if not os.path.exists(graphs_folder):\n",
    "    os.makedirs(graphs_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the temp evolution\n",
    "plt.figure()\n",
    "plt.plot(vaclog_new[\"Time\"],vaclog_new[\"CernOx Temp\"],marker=\".\", markersize=5,label='T-CERNOX')          \n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.legend()\n",
    "plt.title(\"Temperature evolution\")\n",
    "plt.yscale('linear')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "for label in ax.get_xticklabels(which='major'):\n",
    "    label.set(rotation=30, horizontalalignment='right')    \n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder,\"Temp.png\"),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helium level\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_val, y_val, marker=\".\", markersize=5, label='inj volume pressure')\n",
    "ax.plot(x_fit, y_fit, \"--\", color=\"red\", label=f\"Fitted line: y = {a:.4f}*x+{b:.2f}\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('LHe level (mm)')\n",
    "ax.set_yscale('linear')\n",
    "\n",
    "plt.title(\"Helium level drop and fit\")\n",
    "plt.savefig(os.path.join(graphs_folder, 'He_level.png'), dpi=300,bbox_inches='tight')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting BA2, BA1 pressure\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(data[\".\\\\vaclog\"][\"Time\"],data[\".\\\\vaclog\"][\"Barion_2\"],marker=\".\", markersize=4,label='Barion 2')\n",
    "plt.plot(data[\".\\\\vaclog\"][\"Time\"],data[\".\\\\vaclog\"][\"Barion_1\"],marker=\".\", markersize=4,label='Barion 1')\n",
    "plt.plot(data[\".\\\\vaclog\"][\"Time\"],data[\".\\\\vaclog\"][\"DUAL experiment\"],marker=\".\", markersize=4,label='DUAL experiment')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Pressure (mbar)')\n",
    "plt.legend()\n",
    "plt.title(\"Ads isotherm gauge readings as read\")\n",
    "plt.yscale('log')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "for label in ax.get_xticklabels(which='major'):\n",
    "    label.set(rotation=30, horizontalalignment='right')    \n",
    "\n",
    "#Writing comments as plot annotations\n",
    "trans  = transforms.blended_transform_factory(\n",
    "    ax.transData, ax.transAxes)\n",
    "for i in vaclog_comments.index:\n",
    "    plt.text(vaclog_comments[\"Time\"][i],0.8,str(vaclog_comments[\"Live comments\"][i]),fontdict=font, transform=trans)      \n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder, './H2 adsorption isotherm_N2 equiv pressures.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the thermal transpiration corrected H2 equiv. gauge readings\n",
    "print(data[\".\\\\vaclog\"][\"Time\"])\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(vaclog_new[\"Time\"],vaclog_new[\"Barion_1 corr\"],marker=\".\", markersize=4,label='Barion 1')\n",
    "plt.plot(vaclog_new[\"Time\"],vaclog_new[\"Barion_2 corr\"],marker=\".\", markersize=4,label='Barion 2')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Pressure (mbar)')\n",
    "plt.legend()\n",
    "plt.title(\"Ads isotherm gauge readings H2 equiv\")\n",
    "plt.yscale('log')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "for label in ax.get_xticklabels(which='major'):\n",
    "    label.set(rotation=30, horizontalalignment='right') \n",
    "       \n",
    "#Writing comments as plot annotations\n",
    "trans  = transforms.blended_transform_factory(\n",
    "    ax.transData, ax.transAxes)\n",
    "for i in vaclog_comments.index:\n",
    "    plt.text(vaclog_comments[\"Time\"][i],0.8,str(vaclog_comments[\"Live comments\"][i]),fontdict=font, transform=trans)      \n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder, 'H2 adsorption isotherm_h2 equiv Pressures.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the adsorption isotherm in low cov range\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(vaclog_new[\"Coverage\"],vaclog_new[\"Barion_2 corr\"],marker=\".\", markersize=5,label='p vs cov')\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel('Coverage (M/cm2)')\n",
    "ax.set_ylabel('Pressure (mbar)')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(0, 1e15)\n",
    "plt.title(\"H2 adsorption isotherm, zoomed-in to low cov\")\n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder, 'H2 adsorption isotherm.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the adsorption isotherms up to 1e16 M/cm2\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#my data\n",
    "ax.plot(vaclog_new[\"Coverage\"],vaclog_new[\"Barion_2 corr\"],marker=\".\", markersize=5,label='my isotherm, lumped inj')\n",
    "\n",
    "#E. Wallen's data\n",
    "ax.plot(data_wallen[\"Surface coverage [molecules per cm^2]\"],data_wallen[\"Pressure [mbar]\"],marker=\".\", markersize=5,label='E. Wallen isotherm')\n",
    "\n",
    "#Fleur's data TODO\n",
    "ax.plot(data_fleur[\"Coverage (molecules/cm^2).2\"],data_fleur[\"Pressure Barion gauge (mbar)\"],marker=\".\", markersize=5,label='Fleurs isotherm')\n",
    "ax.set_xlim(0, 1e16)\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlabel('Coverage (M/cm2)')\n",
    "ax.set_ylabel('Pressure (mbar)')\n",
    "ax.set_yscale('log')\n",
    "plt.title(\"H2 adsorption isotherm\")\n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder, 'H2 adsorption isotherm.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the theoretical isotherms + \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(theta_drk(fit_values,d_CWB),fit_values,marker=\".\", markersize=5,label='Chill, Wilfert, Bozyk isotherm')\n",
    "ax.plot(theta_hobson(fit_values),fit_values,marker=\".\", markersize=5,label='Hobson isotherm')\n",
    "ax.plot(theta_drk(data_wallen[\"Pressure [mbar]\"]*100,d_wallen),data_wallen[\"Pressure [mbar]\"]*100,marker=\".\", markersize=5,label='Fit based on E. Wallen data isotherm')\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel('Coverage (M/cm2)')\n",
    "ax.set_ylabel('Pressure (Pa)')\n",
    "ax.set_yscale('log')\n",
    "plt.title(\"H2 adsorption isotherm fits from theory\")\n",
    "\n",
    "plt.savefig(os.path.join(graphs_folder, 'Theoretical isotherms.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute writing data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(\"adsorption isotherms_Tiirinen.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
